---
title: Google Cloud Platform (GCP) Best Practices
description: GCP platform engineering patterns, Cloud Build, Terraform for GCP, and cloud architecture best practices
priority: 290
alwaysApply: false
files:
  include:
    - "**/cloudbuild.yaml"
    - "**/*.tf" # Terraform for GCP
    - "**/app.yaml" # App Engine
    - "**/Dockerfile" # Cloud Run
---

# Google Cloud Platform (GCP) Best Practices

## Guiding Principles

1. **Cloud-Native Services**: Leverage GCP-managed services (Cloud Run, Cloud Functions, GKE Autopilot)
2. **Infrastructure as Code**: Terraform for GCP resources, Cloud Build for CI/CD
3. **Security First**: IAM with service accounts, Secret Manager, VPC Service Controls
4. **Cost Efficiency**: Committed use discounts, preemptible VMs, auto-scaling
5. **Observability**: Cloud Logging, Cloud Monitoring, Cloud Trace

---

## GCP Resource Naming Convention

### Standard Format
```
{resource-type}-{project}-{environment}-{region}-{instance}
```

### Examples
```bash
# Compute Instance
vm-webapp-prod-us-central1-001

# Cloud Storage Bucket (globally unique)
acme-webapp-prod-storage

# Cloud Run Service
webapp-prod-us-central1

# Cloud Function
function-process-images-prod

# GKE Cluster
gke-webapp-prod-us-central1

# Cloud SQL Instance
sql-webapp-prod-us-central1-001

# VPC Network
vpc-webapp-prod
```

---

## Terraform for GCP

### Provider Configuration
```hcl
# versions.tf
terraform {
  required_version = ">= 1.6"

  required_providers {
    google = {
      source  = "hashicorp/google"
      version = "~> 5.0"
    }
    google-beta = {
      source  = "hashicorp/google-beta"
      version = "~> 5.0"
    }
  }

  backend "gcs" {
    bucket = "acme-terraform-state"
    prefix = "webapp/prod"
  }
}

provider "google" {
  project = var.project_id
  region  = var.region
}

provider "google-beta" {
  project = var.project_id
  region  = var.region
}
```

### Cloud Run Service
```hcl
# cloud-run.tf
resource "google_cloud_run_v2_service" "webapp" {
  name     = "webapp-${var.environment}"
  location = var.region

  template {
    scaling {
      min_instance_count = var.environment == "prod" ? 2 : 0
      max_instance_count = var.environment == "prod" ? 100 : 10
    }

    containers {
      image = "gcr.io/${var.project_id}/webapp:${var.image_tag}"

      resources {
        limits = {
          cpu    = "1000m"
          memory = "512Mi"
        }
        cpu_idle = true
      }

      ports {
        container_port = 8080
      }

      env {
        name  = "ENVIRONMENT"
        value = var.environment
      }

      env {
        name = "DATABASE_URL"
        value_source {
          secret_key_ref {
            secret  = google_secret_manager_secret.db_url.secret_id
            version = "latest"
          }
        }
      }

      startup_probe {
        http_get {
          path = "/health"
          port = 8080
        }
        initial_delay_seconds = 5
        period_seconds        = 10
        failure_threshold     = 3
      }

      liveness_probe {
        http_get {
          path = "/health"
          port = 8080
        }
        period_seconds    = 30
        failure_threshold = 3
      }
    }

    service_account = google_service_account.webapp.email
  }

  traffic {
    type    = "TRAFFIC_TARGET_ALLOCATION_TYPE_LATEST"
    percent = 100
  }

  depends_on = [google_project_service.cloudrun]
}

# IAM for Cloud Run (public or authenticated)
resource "google_cloud_run_service_iam_member" "public" {
  count = var.allow_public_access ? 1 : 0

  service  = google_cloud_run_v2_service.webapp.name
  location = google_cloud_run_v2_service.webapp.location
  role     = "roles/run.invoker"
  member   = "allUsers"
}

# Output the service URL
output "cloud_run_url" {
  value = google_cloud_run_v2_service.webapp.uri
}
```

### Cloud Storage Bucket
```hcl
resource "google_storage_bucket" "webapp_storage" {
  name          = "${var.project_id}-${var.environment}-storage"
  location      = var.region
  force_destroy = false

  uniform_bucket_level_access = true

  versioning {
    enabled = true
  }

  lifecycle_rule {
    condition {
      age = 30
    }
    action {
      type          = "SetStorageClass"
      storage_class = "NEARLINE"
    }
  }

  lifecycle_rule {
    condition {
      age = 90
    }
    action {
      type          = "SetStorageClass"
      storage_class = "COLDLINE"
    }
  }

  encryption {
    default_kms_key_name = google_kms_crypto_key.storage_key.id
  }

  labels = {
    environment = var.environment
    managed_by  = "terraform"
  }
}

# Bucket IAM
resource "google_storage_bucket_iam_member" "webapp_storage_admin" {
  bucket = google_storage_bucket.webapp_storage.name
  role   = "roles/storage.objectAdmin"
  member = "serviceAccount:${google_service_account.webapp.email}"
}
```

### Cloud SQL (PostgreSQL)
```hcl
resource "google_sql_database_instance" "postgres" {
  name             = "sql-webapp-${var.environment}"
  database_version = "POSTGRES_15"
  region           = var.region

  settings {
    tier              = var.environment == "prod" ? "db-custom-2-8192" : "db-f1-micro"
    availability_type = var.environment == "prod" ? "REGIONAL" : "ZONAL"
    disk_type         = "PD_SSD"
    disk_size         = var.environment == "prod" ? 100 : 10
    disk_autoresize   = true

    backup_configuration {
      enabled                        = true
      start_time                     = "02:00"
      point_in_time_recovery_enabled = var.environment == "prod"
      transaction_log_retention_days = 7
      backup_retention_settings {
        retained_backups = 30
      }
    }

    ip_configuration {
      ipv4_enabled    = false
      private_network = google_compute_network.vpc.id
      require_ssl     = true
    }

    database_flags {
      name  = "log_checkpoints"
      value = "on"
    }

    database_flags {
      name  = "log_connections"
      value = "on"
    }

    insights_config {
      query_insights_enabled  = true
      query_plans_per_minute  = 5
      query_string_length     = 1024
      record_application_tags = true
    }
  }

  deletion_protection = var.environment == "prod"

  depends_on = [google_project_service.sqladmin]
}

resource "google_sql_database" "database" {
  name     = "webapp"
  instance = google_sql_database_instance.postgres.name
}

resource "google_sql_user" "webapp" {
  name     = "webapp"
  instance = google_sql_database_instance.postgres.name
  password = random_password.db_password.result
}
```

---

## GCP CLI (gcloud) Common Operations

### Project Management
```bash
# List projects
gcloud projects list

# Set active project
gcloud config set project PROJECT_ID

# Create new project
gcloud projects create PROJECT_ID --name="Project Name"

# Enable APIs
gcloud services enable compute.googleapis.com
gcloud services enable run.googleapis.com
gcloud services enable cloudbuild.googleapis.com
```

### Cloud Run
```bash
# Deploy service
gcloud run deploy webapp \
  --image gcr.io/PROJECT_ID/webapp:latest \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --memory 512Mi \
  --cpu 1 \
  --min-instances 0 \
  --max-instances 10

# List services
gcloud run services list

# Get service URL
gcloud run services describe webapp \
  --region us-central1 \
  --format 'value(status.url)'

# View logs
gcloud run services logs read webapp --region us-central1

# Delete service
gcloud run services delete webapp --region us-central1
```

### Container Registry

> [!CAUTION]
> **Remote/stateful operations:** `docker push` and image deletions modify remote registries/artifacts.
> Run only with explicit approval and verify the target project/registry/tag.

```bash
# Authenticate Docker to GCR
gcloud auth configure-docker

# Build and push image
docker build -t gcr.io/PROJECT_ID/webapp:v1.0.0 .
docker push gcr.io/PROJECT_ID/webapp:v1.0.0

# List images
gcloud container images list --repository=gcr.io/PROJECT_ID

# Delete old images
gcloud container images delete gcr.io/PROJECT_ID/webapp:v1.0.0 --quiet
```

### Cloud Build
```bash
# Submit build
gcloud builds submit --config cloudbuild.yaml

# List builds
gcloud builds list --limit 10

# View build logs
gcloud builds log BUILD_ID

# Cancel build
gcloud builds cancel BUILD_ID
```

---

## Cloud Build CI/CD

### Build Configuration
```yaml
# cloudbuild.yaml
steps:
  # Run tests
  - name: 'node:20'
    entrypoint: npm
    args: ['ci']

  - name: 'node:20'
    entrypoint: npm
    args: ['test']

  - name: 'node:20'
    entrypoint: npm
    args: ['run', 'build']

  # Build Docker image
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '-t'
      - 'gcr.io/$PROJECT_ID/webapp:$COMMIT_SHA'
      - '-t'
      - 'gcr.io/$PROJECT_ID/webapp:latest'
      - '.'

  # Push to Container Registry
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - 'gcr.io/$PROJECT_ID/webapp:$COMMIT_SHA'

  # Deploy to Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: gcloud
    args:
      - 'run'
      - 'deploy'
      - 'webapp-prod'
      - '--image'
      - 'gcr.io/$PROJECT_ID/webapp:$COMMIT_SHA'
      - '--region'
      - 'us-central1'
      - '--platform'
      - 'managed'
      - '--memory'
      - '512Mi'
      - '--min-instances'
      - '2'
      - '--max-instances'
      - '100'
      - '--allow-unauthenticated'

# Store images in Container Registry
images:
  - 'gcr.io/$PROJECT_ID/webapp:$COMMIT_SHA'
  - 'gcr.io/$PROJECT_ID/webapp:latest'

# Build options
options:
  machineType: 'N1_HIGHCPU_8'
  substitutionOption: 'ALLOW_LOOSE'
  logging: CLOUD_LOGGING_ONLY

# Timeout
timeout: 1200s

# Substitutions (can be overridden)
substitutions:
  _ENVIRONMENT: 'production'
```

### Trigger Configuration
```yaml
# cloudbuild-trigger.yaml
name: webapp-prod-deploy
description: Deploy to production on main branch push
filename: cloudbuild.yaml

github:
  owner: acme
  name: webapp
  push:
    branch: ^main$

includedFiles:
  - 'src/**'
  - 'Dockerfile'
  - 'package.json'
  - 'cloudbuild.yaml'

substitutions:
  _ENVIRONMENT: production
  _REGION: us-central1
```

---

## Service Accounts & IAM

### Service Account Creation
```hcl
# Service account for Cloud Run
resource "google_service_account" "webapp" {
  account_id   = "webapp-${var.environment}"
  display_name = "Web Application Service Account (${var.environment})"
  description  = "Service account for webapp Cloud Run service"
}

# Grant necessary permissions
resource "google_project_iam_member" "webapp_logging" {
  project = var.project_id
  role    = "roles/logging.logWriter"
  member  = "serviceAccount:${google_service_account.webapp.email}"
}

resource "google_project_iam_member" "webapp_monitoring" {
  project = var.project_id
  role    = "roles/monitoring.metricWriter"
  member  = "serviceAccount:${google_service_account.webapp.email}"
}

resource "google_project_iam_member" "webapp_trace" {
  project = var.project_id
  role    = "roles/cloudtrace.agent"
  member  = "serviceAccount:${google_service_account.webapp.email}"
}
```

### Workload Identity (GKE)
```hcl
# Bind Kubernetes service account to GCP service account
resource "google_service_account_iam_member" "workload_identity" {
  service_account_id = google_service_account.webapp.name
  role               = "roles/iam.workloadIdentityUser"
  member             = "serviceAccount:${var.project_id}.svc.id.goog[${var.k8s_namespace}/${var.k8s_service_account}]"
}
```

---

## Secret Manager

### Store Secrets
```hcl
resource "google_secret_manager_secret" "db_password" {
  secret_id = "db-password-${var.environment}"

  replication {
    automatic = true
  }

  labels = {
    environment = var.environment
    managed_by  = "terraform"
  }
}

resource "google_secret_manager_secret_version" "db_password" {
  secret      = google_secret_manager_secret.db_password.id
  secret_data = random_password.db_password.result
}

# Grant access to service account
resource "google_secret_manager_secret_iam_member" "webapp_db_password" {
  secret_id = google_secret_manager_secret.db_password.id
  role      = "roles/secretmanager.secretAccessor"
  member    = "serviceAccount:${google_service_account.webapp.email}"
}
```

### Access Secrets in Code
```javascript
// Node.js example
const { SecretManagerServiceClient } = require('@google-cloud/secret-manager');

const client = new SecretManagerServiceClient();

async function getSecret(secretName) {
  const name = `projects/${process.env.GCP_PROJECT}/secrets/${secretName}/versions/latest`;

  const [version] = await client.accessSecretVersion({ name });
  const payload = version.payload.data.toString('utf8');

  return payload;
}

// Usage
const dbPassword = await getSecret('db-password-prod');
```

---

## Cloud Functions (2nd Gen)

### Function Deployment
```hcl
resource "google_cloudfunctions2_function" "image_processor" {
  name     = "process-images-${var.environment}"
  location = var.region

  build_config {
    runtime     = "nodejs20"
    entry_point = "processImage"

    source {
      storage_source {
        bucket = google_storage_bucket.function_source.name
        object = google_storage_bucket_object.function_zip.name
      }
    }
  }

  service_config {
    max_instance_count = 100
    min_instance_count = 0
    available_memory   = "256M"
    timeout_seconds    = 60

    environment_variables = {
      ENVIRONMENT = var.environment
    }

    secret_environment_variables {
      key        = "API_KEY"
      project_id = var.project_id
      secret     = "api-key"
      version    = "latest"
    }

    service_account_email = google_service_account.function.email
  }

  event_trigger {
    trigger_region = var.region
    event_type     = "google.cloud.storage.object.v1.finalized"

    event_filters {
      attribute = "bucket"
      value     = google_storage_bucket.uploads.name
    }
  }
}
```

### Function Code (index.js)
```javascript
const functions = require('@google-cloud/functions-framework');
const { Storage } = require('@google-cloud/storage');

functions.cloudEvent('processImage', async (cloudEvent) => {
  console.log('Processing image:', cloudEvent.data.name);

  const storage = new Storage();
  const file = storage.bucket(cloudEvent.data.bucket).file(cloudEvent.data.name);

  // Process image (resize, optimize, etc.)
  // ...

  console.log('Image processed successfully');
});
```

---

## GKE (Google Kubernetes Engine)

### GKE Autopilot Cluster
```hcl
resource "google_container_cluster" "primary" {
  name     = "gke-${var.environment}"
  location = var.region

  # Autopilot mode (fully managed)
  enable_autopilot = true

  # VPC-native cluster
  ip_allocation_policy {}

  # Release channel
  release_channel {
    channel = var.environment == "prod" ? "REGULAR" : "RAPID"
  }

  # Workload Identity
  workload_identity_config {
    workload_pool = "${var.project_id}.svc.id.goog"
  }

  # Network security
  private_cluster_config {
    enable_private_nodes    = true
    enable_private_endpoint = false
    master_ipv4_cidr_block  = "172.16.0.0/28"
  }

  # Master authorized networks
  master_authorized_networks_config {
    cidr_blocks {
      cidr_block   = "0.0.0.0/0"
      display_name = "All"
    }
  }

  # Logging and monitoring
  logging_config {
    enable_components = ["SYSTEM_COMPONENTS", "WORKLOADS"]
  }

  monitoring_config {
    enable_components = ["SYSTEM_COMPONENTS"]

    managed_prometheus {
      enabled = true
    }
  }
}
```

---

## Monitoring & Logging

### Log-based Metrics
```hcl
resource "google_logging_metric" "error_rate" {
  name   = "error-rate-${var.environment}"
  filter = <<-EOT
    resource.type="cloud_run_revision"
    resource.labels.service_name="webapp-${var.environment}"
    severity>=ERROR
  EOT

  metric_descriptor {
    metric_kind = "DELTA"
    value_type  = "INT64"
    unit        = "1"

    labels {
      key         = "service"
      value_type  = "STRING"
      description = "Service name"
    }
  }

  label_extractors = {
    "service" = "EXTRACT(resource.labels.service_name)"
  }
}
```

### Uptime Check
```hcl
resource "google_monitoring_uptime_check_config" "webapp" {
  display_name = "webapp-${var.environment}-uptime"
  timeout      = "10s"
  period       = "60s"

  http_check {
    path           = "/health"
    port           = "443"
    use_ssl        = true
    validate_ssl   = true
    request_method = "GET"
  }

  monitored_resource {
    type = "uptime_url"
    labels = {
      project_id = var.project_id
      host       = google_cloud_run_v2_service.webapp.uri
    }
  }

  content_matchers {
    content = "\"status\":\"healthy\""
    matcher = "CONTAINS_STRING"
  }
}
```

### Alert Policy
```hcl
resource "google_monitoring_alert_policy" "high_error_rate" {
  display_name = "High Error Rate - ${var.environment}"
  combiner     = "OR"

  conditions {
    display_name = "Error rate > 5%"

    condition_threshold {
      filter          = "metric.type=\"logging.googleapis.com/user/${google_logging_metric.error_rate.name}\" resource.type=\"cloud_run_revision\""
      duration        = "300s"
      comparison      = "COMPARISON_GT"
      threshold_value = 5

      aggregations {
        alignment_period   = "60s"
        per_series_aligner = "ALIGN_RATE"
      }
    }
  }

  notification_channels = [google_monitoring_notification_channel.email.id]

  alert_strategy {
    auto_close = "604800s" # 7 days
  }
}
```

---

## Best Practices Checklist

### Security
- [ ] Use service accounts (not user accounts) for applications
- [ ] Store secrets in Secret Manager
- [ ] Enable VPC Service Controls for sensitive data
- [ ] Use private IP for Cloud SQL
- [ ] Implement least privilege IAM
- [ ] Enable audit logging
- [ ] Use Cloud Armor for DDoS protection
- [ ] Regular security scanning with Security Command Center

### Cost Optimization
- [ ] Use committed use discounts for predictable workloads
- [ ] Leverage preemptible VMs for batch processing
- [ ] Implement auto-scaling
- [ ] Use Cloud Storage lifecycle policies
- [ ] Right-size compute resources
- [ ] Clean up unused resources
- [ ] Set budget alerts
- [ ] Use labels for cost attribution

### Reliability
- [ ] Deploy across multiple zones/regions
- [ ] Implement health checks
- [ ] Configure auto-scaling
- [ ] Use Cloud SQL automatic backups
- [ ] Monitor with Cloud Monitoring
- [ ] Set up alerts for critical metrics
- [ ] Document disaster recovery procedures
- [ ] Test failover regularly

### Operations
- [ ] Use Infrastructure as Code (Terraform)
- [ ] Implement CI/CD with Cloud Build
- [ ] Use consistent naming conventions
- [ ] Tag all resources with labels
- [ ] Centralized logging with Cloud Logging
- [ ] Implement distributed tracing
- [ ] Document runbooks
- [ ] Automate routine tasks

---

## Related Files

- `280-aws.mdc` - AWS patterns for comparison
- `285-azure.mdc` - Azure patterns for comparison
- `140-terraform.mdc` - Terraform best practices
- `260-kubernetes.mdc` - Kubernetes patterns (for GKE)
- `310-security.mdc` - Security best practices

---

**Purpose**: Google Cloud Platform engineering and best practices
